#!/usr/bin/env python3
"""
Test script for Luckin Coffee Analytics Dashboard
Tests all data processing and visualization functions
"""

import pandas as pd
import numpy as np
from datetime import datetime
import sys

def test_data_processing():
    """Test all data processing functions"""
    print("=" * 60)
    print("Testing Data Processing Functions")
    print("=" * 60)
    
    results = []
    
    # Test DoorDash
    print("\nğŸ“Š Testing DoorDash Processing...")
    try:
        df = pd.read_csv('/mnt/user-data/uploads/doordash.csv')
        processed = pd.DataFrame()
        processed['Date'] = pd.to_datetime(df['æ—¶é—´æˆ³æœ¬åœ°æ—¥æœŸ'], errors='coerce')
        processed['Platform'] = 'DoorDash'
        processed['Revenue'] = pd.to_numeric(df['å‡€æ€»è®¡'], errors='coerce')
        
        # Clean
        processed = processed[processed['Date'].notna()]
        processed = processed[processed['Revenue'].notna()]
        
        print(f"âœ… DoorDash: {len(processed)} valid orders")
        print(f"   Date range: {processed['Date'].min()} to {processed['Date'].max()}")
        print(f"   Total revenue: ${processed['Revenue'].sum():,.2f}")
        results.append(processed)
    except Exception as e:
        print(f"âŒ DoorDash Error: {e}")
    
    # Test Uber
    print("\nğŸ“Š Testing Uber Processing...")
    try:
        df = pd.read_csv('/mnt/user-data/uploads/Uber.csv')
        
        # Fix headers
        if 'Uber Eats ä¼˜é£Ÿç®¡ç†å·¥å…·ä¸­æ˜¾ç¤ºçš„é¤å…åç§°' in str(df.columns[0]):
            header_row = df.iloc[0]
            new_columns = [str(val).strip() if not pd.isna(val) else '' for val in header_row]
            df.columns = new_columns
            df = df.iloc[1:].reset_index(drop=True)
        
        df.columns = [col if col else f'col_{i}' for i, col in enumerate(df.columns)]
        
        processed = pd.DataFrame()
        processed['Date'] = pd.to_datetime(df['è®¢å•æ—¥æœŸ'], format='%m/%d/%Y', errors='coerce')
        processed['Revenue'] = pd.to_numeric(df['æ”¶å…¥æ€»é¢'], errors='coerce')
        processed['Platform'] = 'Uber'
        
        # Clean
        processed = processed[processed['Date'].notna()]
        processed = processed[processed['Revenue'].notna()]
        processed = processed[processed['Revenue'] != 0]
        
        print(f"âœ… Uber: {len(processed)} valid orders")
        print(f"   Date range: {processed['Date'].min()} to {processed['Date'].max()}")
        print(f"   Total revenue: ${processed['Revenue'].sum():,.2f}")
        results.append(processed)
    except Exception as e:
        print(f"âŒ Uber Error: {e}")
    
    # Test Grubhub
    print("\nğŸ“Š Testing Grubhub Processing...")
    try:
        df = pd.read_csv('/mnt/user-data/uploads/grubhub.csv')
        
        processed = pd.DataFrame()
        # Use fallback date for corrupted dates
        start_date = pd.to_datetime('2025-10-01')
        date_range = pd.date_range(start=start_date, periods=len(df), freq='H')
        processed['Date'] = date_range[:len(df)]
        
        processed['Revenue'] = pd.to_numeric(df['merchant_net_total'], errors='coerce')
        processed['Platform'] = 'Grubhub'
        
        # Clean
        processed = processed[processed['Revenue'].notna()]
        processed = processed[processed['Revenue'] != 0]
        
        print(f"âœ… Grubhub: {len(processed)} valid orders")
        print(f"   Date range: {processed['Date'].min()} to {processed['Date'].max()}")
        print(f"   Total revenue: ${processed['Revenue'].sum():,.2f}")
        results.append(processed)
    except Exception as e:
        print(f"âŒ Grubhub Error: {e}")
    
    return results

def test_visualizations(data_frames):
    """Test visualization data preparation"""
    print("\n" + "=" * 60)
    print("Testing Visualization Data")
    print("=" * 60)
    
    if not data_frames:
        print("âŒ No data available for visualization")
        return
    
    # Combine all data
    df = pd.concat(data_frames, ignore_index=True)
    print(f"\nğŸ“Š Combined Dataset:")
    print(f"   Total orders: {len(df):,}")
    print(f"   Total revenue: ${df['Revenue'].sum():,.2f}")
    print(f"   Platforms: {', '.join(df['Platform'].unique())}")
    
    # Platform breakdown
    print("\nğŸ“± Platform Breakdown:")
    platform_stats = df.groupby('Platform').agg({
        'Revenue': ['count', 'sum', 'mean']
    }).round(2)
    platform_stats.columns = ['Orders', 'Total Revenue', 'AOV']
    print(platform_stats)
    
    # Daily revenue
    print("\nğŸ“ˆ Daily Revenue Stats:")
    daily_revenue = df.groupby('Date')['Revenue'].sum()
    print(f"   Average daily revenue: ${daily_revenue.mean():.2f}")
    print(f"   Max daily revenue: ${daily_revenue.max():.2f}")
    print(f"   Min daily revenue: ${daily_revenue.min():.2f}")
    
    return True

def main():
    print("Luckin Coffee Analytics Dashboard - Data Test")
    print("=" * 60)
    
    # Test data processing
    data_frames = test_data_processing()
    
    # Test visualizations
    if data_frames:
        test_visualizations(data_frames)
        print("\nâœ… All tests passed! Data is ready for visualization.")
    else:
        print("\nâŒ No data processed successfully.")
        return 1
    
    return 0

if __name__ == "__main__":
    sys.exit(main())
